<!DOCTYPE html><html lang="en-us" >

<head>

  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="generator" content="Source Themes Academic 4.8.0">

  

  
  
  
  
  
    
    
    
  
  

  <meta name="author" content="He Zhang (David)">

  
  
  
    
  
  <meta name="description" content="This paper presents VCU-RVI, a new visual inertial odometry (VIO) benchmark with a set of diverse data sequences in different indoor scenarios. The benchmark is captured using an Structure Core (SC) sensor, consisting of RGB-D camera and an IMU. It provides aligned color and depth images with 640x480 resolution at 30 Hz. The camera&#39;s data is synchronized with the IMU&#39;s data at 100 Hz. Thirty-nine data sequences covering a total of ~3.7 kilometers trajectory are recorded in various indoor environments by two experimental setups$:$ holding it by a hand or installing it on a wheeled robot. For the handheld SC data sequences in the laboratory, they are recorded under three challenging conditions$:$ fast motion, radical illumination changing, and dynamic objects. Besides, data sequences for long distance indoor navigation are collected covering different indoor scenarios$:$ room, corridor, hall, and stairway. For the data sequences captured using the wheeled robot, half of them are recorded with sufficient IMU excitation in the beginning of the sequence, allowing to test the VIO methods with the requirement of sufficient motion conditions for initialization. We also put three bumpers in the laboratory to simulate bumpy road scenarios where the robot&#39;s motion is of 6-DOF. In addition, data sequences for long distance travel are also collected by the wheel robot. For trajectory evaluation, we use a motion capture system (120 Hz) to provide accurate pose ground truth. We conduct experiments to evaluate state-of-the-art VIO algorithms using our benchmark. The VCU-RVI dataset, the evaluated VIO methods, and the evaluation tools to generate the experimental results are made public.">

  
  <link rel="alternate" hreflang="en-us" href="https://rising-turtle.github.io/david_zhang/publication/iros-20-2/">

  


  
  
  
  <meta name="theme-color" content="#3f51b5">
  

  
  
  
  <script src="/david_zhang/js/mathjax-config.js"></script>
  

  
  
  
  
    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.8.6/css/academicons.min.css" integrity="sha256-uFVgMKfistnJAfoCUQigIl+JfUaP47GrRKjf6CTPVmw=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.0-1/css/all.min.css" integrity="sha256-4w9DunooKSr3MFXHXWyFER38WmPdm361bQS/2KUWZbU=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.css" integrity="sha256-Vzbj7sDDS/woiFS3uNKo8eIuni59rjyNGtXfstRzStA=" crossorigin="anonymous">

    
    
    
      
    
    
      
      
        
          <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.18.1/styles/github.min.css" crossorigin="anonymous" title="hl-light">
          <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.18.1/styles/dracula.min.css" crossorigin="anonymous" title="hl-dark" disabled>
        
      
    

    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/leaflet/1.5.1/leaflet.css" integrity="sha256-SHMGCYmST46SoyGgo4YR/9AlK1vf3ff84Aq9yK4hdqM=" crossorigin="anonymous">
    

    

    
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
        <script src="https://cdnjs.cloudflare.com/ajax/libs/lazysizes/5.1.2/lazysizes.min.js" integrity="sha256-Md1qLToewPeKjfAHU1zyPwOutccPAm5tahnaw7Osw0A=" crossorigin="anonymous" async></script>
      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
        <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js" integrity="" crossorigin="anonymous" async></script>
      
    
      

      
      

      
    

  

  
  
  
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Montserrat:400,700%7CRoboto:400,400italic,700%7CRoboto+Mono&display=swap">
  

  
  
  
  
  <link rel="stylesheet" href="/david_zhang/css/academic.css">

  




  


  
  

  

  <link rel="manifest" href="/david_zhang/index.webmanifest">
  <link rel="icon" type="image/png" href="/david_zhang/images/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_32x32_fill_lanczos_center_2.png">
  <link rel="apple-touch-icon" type="image/png" href="/david_zhang/images/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_192x192_fill_lanczos_center_2.png">

  <link rel="canonical" href="https://rising-turtle.github.io/david_zhang/publication/iros-20-2/">

  
  
  
  
  
  
  
    
  
  
  <meta property="twitter:card" content="summary_large_image">
  
  <meta property="og:site_name" content="Academic">
  <meta property="og:url" content="https://rising-turtle.github.io/david_zhang/publication/iros-20-2/">
  <meta property="og:title" content="The VCU-RVI Benchmark: Evaluating Visual Inertial Odometry for Indoor Navigation Applications with an RGB-D Camera | Academic">
  <meta property="og:description" content="This paper presents VCU-RVI, a new visual inertial odometry (VIO) benchmark with a set of diverse data sequences in different indoor scenarios. The benchmark is captured using an Structure Core (SC) sensor, consisting of RGB-D camera and an IMU. It provides aligned color and depth images with 640x480 resolution at 30 Hz. The camera&#39;s data is synchronized with the IMU&#39;s data at 100 Hz. Thirty-nine data sequences covering a total of ~3.7 kilometers trajectory are recorded in various indoor environments by two experimental setups$:$ holding it by a hand or installing it on a wheeled robot. For the handheld SC data sequences in the laboratory, they are recorded under three challenging conditions$:$ fast motion, radical illumination changing, and dynamic objects. Besides, data sequences for long distance indoor navigation are collected covering different indoor scenarios$:$ room, corridor, hall, and stairway. For the data sequences captured using the wheeled robot, half of them are recorded with sufficient IMU excitation in the beginning of the sequence, allowing to test the VIO methods with the requirement of sufficient motion conditions for initialization. We also put three bumpers in the laboratory to simulate bumpy road scenarios where the robot&#39;s motion is of 6-DOF. In addition, data sequences for long distance travel are also collected by the wheel robot. For trajectory evaluation, we use a motion capture system (120 Hz) to provide accurate pose ground truth. We conduct experiments to evaluate state-of-the-art VIO algorithms using our benchmark. The VCU-RVI dataset, the evaluated VIO methods, and the evaluation tools to generate the experimental results are made public."><meta property="og:image" content="https://rising-turtle.github.io/david_zhang/publication/iros-20-2/featured.png">
  <meta property="twitter:image" content="https://rising-turtle.github.io/david_zhang/publication/iros-20-2/featured.png"><meta property="og:locale" content="en-us">
  
    
      <meta property="article:published_time" content="2017-01-01T00:00:00&#43;00:00">
    
    <meta property="article:modified_time" content="2020-10-01T00:00:00&#43;00:00">
  

  


    









<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "Article",
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://rising-turtle.github.io/david_zhang/publication/iros-20-2/"
  },
  "headline": "The VCU-RVI Benchmark: Evaluating Visual Inertial Odometry for Indoor Navigation Applications with an RGB-D Camera",
  
  "image": [
    "https://rising-turtle.github.io/david_zhang/publication/iros-20-2/featured.png"
  ],
  
  "datePublished": "2017-01-01T00:00:00Z",
  "dateModified": "2020-10-01T00:00:00Z",
  
  "author": {
    "@type": "Person",
    "name": "He Zhang"
  },
  
  "publisher": {
    "@type": "Organization",
    "name": "Academic",
    "logo": {
      "@type": "ImageObject",
      "url": "https://rising-turtle.github.io/david_zhang/images/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_192x192_fill_lanczos_center_2.png"
    }
  },
  "description": "This paper presents VCU-RVI, a new visual inertial odometry (VIO) benchmark with a set of diverse data sequences in different indoor scenarios. The benchmark is captured using an Structure Core (SC) sensor, consisting of RGB-D camera and an IMU. It provides aligned color and depth images with 640x480 resolution at 30 Hz. The camera's data is synchronized with the IMU's data at 100 Hz. Thirty-nine data sequences covering a total of ~3.7 kilometers trajectory are recorded in various indoor environments by two experimental setups$:$ holding it by a hand or installing it on a wheeled robot. For the handheld SC data sequences in the laboratory, they are recorded under three challenging conditions$:$ fast motion, radical illumination changing, and dynamic objects. Besides, data sequences for long distance indoor navigation are collected covering different indoor scenarios$:$ room, corridor, hall, and stairway. For the data sequences captured using the wheeled robot, half of them are recorded with sufficient IMU excitation in the beginning of the sequence, allowing to test the VIO methods with the requirement of sufficient motion conditions for initialization. We also put three bumpers in the laboratory to simulate bumpy road scenarios where the robot's motion is of 6-DOF. In addition, data sequences for long distance travel are also collected by the wheel robot. For trajectory evaluation, we use a motion capture system (120 Hz) to provide accurate pose ground truth. We conduct experiments to evaluate state-of-the-art VIO algorithms using our benchmark. The VCU-RVI dataset, the evaluated VIO methods, and the evaluation tools to generate the experimental results are made public."
}
</script>

  

  


  


  





  <title>The VCU-RVI Benchmark: Evaluating Visual Inertial Odometry for Indoor Navigation Applications with an RGB-D Camera | Academic</title>

</head>

<body id="top" data-spy="scroll" data-offset="70" data-target="#TableOfContents" >

  <aside class="search-results" id="search">
  <div class="container">
    <section class="search-header">

      <div class="row no-gutters justify-content-between mb-3">
        <div class="col-6">
          <h1>Search</h1>
        </div>
        <div class="col-6 col-search-close">
          <a class="js-search" href="#"><i class="fas fa-times-circle text-muted" aria-hidden="true"></i></a>
        </div>
      </div>

      <div id="search-box">
        
        <input name="q" id="search-query" placeholder="Search..." autocapitalize="off"
        autocomplete="off" autocorrect="off" spellcheck="false" type="search">
        
      </div>

    </section>
    <section class="section-search-results">

      <div id="search-hits">
        
      </div>

    </section>
  </div>
</aside>


  







<nav class="navbar navbar-expand-lg navbar-light compensate-for-scrollbar" id="navbar-main">
  <div class="container">

    
    <div class="d-none d-lg-inline-flex">
      <a class="navbar-brand" href="/david_zhang/">Academic</a>
    </div>
    

    
    <button type="button" class="navbar-toggler" data-toggle="collapse"
            data-target="#navbar-content" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
    <span><i class="fas fa-bars"></i></span>
    </button>
    

    
    <div class="navbar-brand-mobile-wrapper d-inline-flex d-lg-none">
      <a class="navbar-brand" href="/david_zhang/">Academic</a>
    </div>
    

    
    
    <div class="navbar-collapse main-menu-item collapse justify-content-start" id="navbar-content">

      
      <ul class="navbar-nav d-md-inline-flex">
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/david_zhang/#about"><span>Home</span></a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/david_zhang/#projects"><span>Projects</span></a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/david_zhang/#publications"><span>Publications</span></a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/david_zhang/#contact"><span>Contact</span></a>
        </li>

        
        

      

        
      </ul>
    </div>

    <ul class="nav-icons navbar-nav flex-row ml-auto d-flex pl-md-2">
      
      <li class="nav-item">
        <a class="nav-link js-search" href="#" aria-label="Search"><i class="fas fa-search" aria-hidden="true"></i></a>
      </li>
      

      
      <li class="nav-item dropdown theme-dropdown">
        <a href="#" class="nav-link js-theme-selector" data-toggle="dropdown" aria-haspopup="true">
          <i class="fas fa-palette" aria-hidden="true"></i>
        </a>
        <div class="dropdown-menu">
          <a href="#" class="dropdown-item js-set-theme-light">
            <span>Light</span>
          </a>
          <a href="#" class="dropdown-item js-set-theme-dark">
            <span>Dark</span>
          </a>
          <a href="#" class="dropdown-item js-set-theme-auto">
            <span>Automatic</span>
          </a>
        </div>
      </li>
      

      

    </ul>

  </div>
</nav>


  <div class="pub">

  




















  
  
    
  


<div class="article-container pt-3">
  <h1>The VCU-RVI Benchmark: Evaluating Visual Inertial Odometry for Indoor Navigation Applications with an RGB-D Camera</h1>

  

  


<div class="article-metadata">

  
  
  
  
  <div>
    

  
  <span >He Zhang</span>, <span >Lingqiu Jin</span>, <span >Cang Ye</span>
  </div>
  
  

  
  <span class="article-date">
    
    
      
    
    October 2020
  </span>
  

  

  

  
  
  

  
  

</div>

  













<div class="btn-links mb-3">
  
  








  






  
  
    
  
<a class="btn btn-outline-primary my-1 mr-1" href="https://github.com/rising-turtle/VCU_RVI_Benchmark" target="_blank" rel="noopener">
  Code
</a>




  
    
  




  


  
  
    
  
<a class="btn btn-outline-primary my-1 mr-1" href="https://www.youtube.com/watch?v=sgyO-Rcb7-8" target="_blank" rel="noopener">
  Video
</a>





</div>


</div>


<div class="article-header article-container featured-image-wrapper mt-4 mb-4" style="max-width: 720px; max-height: 534px;">
  <div style="position: relative">
    <img src="/david_zhang/publication/iros-20-2/featured_hu1a264bde755a881d153f6766fb4c8702_1209023_720x0_resize_lanczos_2.png" alt="" class="featured-image">
    
  </div>
</div>



  <div class="article-container">

    
    <h3>Abstract</h3>
    <p class="pub-abstract">This paper presents VCU-RVI, a new visual inertial odometry (VIO) benchmark with a set of diverse data sequences in different indoor scenarios. The benchmark is captured using an Structure Core (SC) sensor, consisting of RGB-D camera and an IMU. It provides aligned color and depth images with 640x480 resolution at 30 Hz. The camera&rsquo;s data is synchronized with the IMU&rsquo;s data at 100 Hz. Thirty-nine data sequences covering a total of ~3.7 kilometers trajectory are recorded in various indoor environments by two experimental setups$:$ holding it by a hand or installing it on a wheeled robot. For the handheld SC data sequences in the laboratory, they are recorded under three challenging conditions$:$ fast motion, radical illumination changing, and dynamic objects. Besides, data sequences for long distance indoor navigation are collected covering different indoor scenarios$:$ room, corridor, hall, and stairway. For the data sequences captured using the wheeled robot, half of them are recorded with sufficient IMU excitation in the beginning of the sequence, allowing to test the VIO methods with the requirement of sufficient motion conditions for initialization. We also put three bumpers in the laboratory to simulate bumpy road scenarios where the robot&rsquo;s motion is of 6-DOF. In addition, data sequences for long distance travel are also collected by the wheel robot. For trajectory evaluation, we use a motion capture system (120 Hz) to provide accurate pose ground truth. We conduct experiments to evaluate state-of-the-art VIO algorithms using our benchmark. The VCU-RVI dataset, the evaluated VIO methods, and the evaluation tools to generate the experimental results are made public.</p>
    

    
    <div class="row">
      <div class="col-md-1"></div>
      <div class="col-md-10">
        <div class="row">
          <div class="col-12 col-md-3 pub-row-heading">Type</div>
          <div class="col-12 col-md-9">
            
            
            <a href="/david_zhang/publication/#1">
              Conference paper
            </a>
            
          </div>
        </div>
      </div>
      <div class="col-md-1"></div>
    </div>
    <div class="d-md-none space-below"></div>
    

    
    <div class="row">
      <div class="col-md-1"></div>
      <div class="col-md-10">
        <div class="row">
          <div class="col-12 col-md-3 pub-row-heading">Publication</div>
          <div class="col-12 col-md-9">In <em>Proceedings of IEEE International Conference on Intelligent Robots and Systems (IROS)</em>, Las Vegas, Oct 25-29</div>
        </div>
      </div>
      <div class="col-md-1"></div>
    </div>
    <div class="d-md-none space-below"></div>
    

    <div class="space-below"></div>

    <div class="article-style"></div>

    








<div class="share-box" aria-hidden="true">
  <ul class="share">
    
      
      
      
        
      
      
      
      <li>
        <a href="https://twitter.com/intent/tweet?url=https://rising-turtle.github.io/david_zhang/publication/iros-20-2/&amp;text=The%20VCU-RVI%20Benchmark:%20Evaluating%20Visual%20Inertial%20Odometry%20for%20Indoor%20Navigation%20Applications%20with%20an%20RGB-D%20Camera" target="_blank" rel="noopener" class="share-btn-twitter">
          <i class="fab fa-twitter"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      <li>
        <a href="https://www.facebook.com/sharer.php?u=https://rising-turtle.github.io/david_zhang/publication/iros-20-2/&amp;t=The%20VCU-RVI%20Benchmark:%20Evaluating%20Visual%20Inertial%20Odometry%20for%20Indoor%20Navigation%20Applications%20with%20an%20RGB-D%20Camera" target="_blank" rel="noopener" class="share-btn-facebook">
          <i class="fab fa-facebook"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      <li>
        <a href="mailto:?subject=The%20VCU-RVI%20Benchmark:%20Evaluating%20Visual%20Inertial%20Odometry%20for%20Indoor%20Navigation%20Applications%20with%20an%20RGB-D%20Camera&amp;body=https://rising-turtle.github.io/david_zhang/publication/iros-20-2/" target="_blank" rel="noopener" class="share-btn-email">
          <i class="fas fa-envelope"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      <li>
        <a href="https://www.linkedin.com/shareArticle?url=https://rising-turtle.github.io/david_zhang/publication/iros-20-2/&amp;title=The%20VCU-RVI%20Benchmark:%20Evaluating%20Visual%20Inertial%20Odometry%20for%20Indoor%20Navigation%20Applications%20with%20an%20RGB-D%20Camera" target="_blank" rel="noopener" class="share-btn-linkedin">
          <i class="fab fa-linkedin-in"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      <li>
        <a href="whatsapp://send?text=The%20VCU-RVI%20Benchmark:%20Evaluating%20Visual%20Inertial%20Odometry%20for%20Indoor%20Navigation%20Applications%20with%20an%20RGB-D%20Camera%20https://rising-turtle.github.io/david_zhang/publication/iros-20-2/" target="_blank" rel="noopener" class="share-btn-whatsapp">
          <i class="fab fa-whatsapp"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      <li>
        <a href="https://service.weibo.com/share/share.php?url=https://rising-turtle.github.io/david_zhang/publication/iros-20-2/&amp;title=The%20VCU-RVI%20Benchmark:%20Evaluating%20Visual%20Inertial%20Odometry%20for%20Indoor%20Navigation%20Applications%20with%20an%20RGB-D%20Camera" target="_blank" rel="noopener" class="share-btn-weibo">
          <i class="fab fa-weibo"></i>
        </a>
      </li>
    
  </ul>
</div>












  
    
    





  


  
    
    





  


  
    
    





  


  












  
  
  <div class="article-widget content-widget-hr">
    <h3>Related</h3>
    <ul>
      
      <li><a href="/david_zhang/publication/wacv-19/">A Comparative Analysis of Visual-Inertial SLAM for Assisted Wayfinding of the Visually Impaired</a></li>
      
      <li><a href="/david_zhang/publication/iros-19-w/">A Depth-Enhanced Visual Inertial Odometry for a Robotic Navigation Aid for Blind People</a></li>
      
      <li><a href="/david_zhang/publication/nsens-18/">A Wearable Robotic Object Manipulation Aid for the Visually Impaired</a></li>
      
      <li><a href="/david_zhang/publication/tmech-20/">Camera Intrinsic Parameters Estimation by Visual Inertial Odometry for a Mobile Phone with Application to Assisted Navigation</a></li>
      
      <li><a href="/david_zhang/publication/ichms-20/">Human-Robot Interaction for Assisted Object Grasping by a Wearable Robotic Object Manipulation Aid for the Blind</a></li>
      
    </ul>
  </div>
  





  </div>
</div>

      

    
    
    
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha256-9/aliU8dGd2tb6OSsuzixeV4y/faTqgFtohetphbbj0=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.imagesloaded/4.1.4/imagesloaded.pkgd.min.js" integrity="sha256-lqvxZrPLtfffUl2G/e7szqSvPBILGbwmsGE1MKlOi0Q=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.isotope/3.0.6/isotope.pkgd.min.js" integrity="sha256-CBrpuqrMhXwcLLUd5tvQ4euBHCdh7wGlDfNz8vbu/iI=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.js" integrity="sha256-yt2kYMy0w8AbtF89WXb2P1rfjcP/HTHLT7097U8Y5b8=" crossorigin="anonymous"></script>

      

      
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.18.1/highlight.min.js" integrity="sha256-eOgo0OtLL4cdq7RdwRUiGKLX9XsIJ7nGhWEKbohmVAQ=" crossorigin="anonymous"></script>
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.18.1/languages/r.min.js"></script>
        
      

    

    
    
      <script src="https://cdnjs.cloudflare.com/ajax/libs/leaflet/1.5.1/leaflet.js" integrity="sha256-EErZamuLefUnbMBQbsEqu1USa+btR2oIlCpBJbyD4/g=" crossorigin="anonymous"></script>
    

    
    
    <script>const code_highlighting = true;</script>
    

    
    
    <script>const isSiteThemeDark = false;</script>
    

    
    
    
    
    
    
    <script>
      const search_config = {"indexURI":"/david_zhang/index.json","minLength":1,"threshold":0.3};
      const i18n = {"no_results":"No results found","placeholder":"Search...","results":"results found"};
      const content_type = {
        'post': "Posts",
        'project': "Projects",
        'publication' : "Publications",
        'talk' : "Talks",
        'slides' : "Slides"
        };
    </script>
    

    
    

    
    
    <script id="search-hit-fuse-template" type="text/x-template">
      <div class="search-hit" id="summary-{{key}}">
      <div class="search-hit-content">
        <div class="search-hit-name">
          <a href="{{relpermalink}}">{{title}}</a>
          <div class="article-metadata search-hit-type">{{type}}</div>
          <p class="search-hit-description">{{snippet}}</p>
        </div>
      </div>
      </div>
    </script>
    

    
    
    <script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/3.2.1/fuse.min.js" integrity="sha256-VzgmKYmhsGNNN4Ph1kMW+BjoYJM2jV5i4IlFoeZA9XI=" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/jquery.mark.min.js" integrity="sha256-4HLtjeVgH0eIB3aZ9mLYF6E8oU5chNdjU6p6rrXpl9U=" crossorigin="anonymous"></script>
    

    
    

    
    

    
    

    
    
    
    
    
    
    
    
    
      
    
    
    
    
    <script src="/david_zhang/js/academic.min.37431be2d92d7fb0160054761ab79602.js"></script>

    






  
  
  <div class="container">
    <footer class="site-footer">
  

  <p class="powered-by">
    
  </p>

  
  






  <p class="powered-by">
    Powered by the
    <a href="https://sourcethemes.com/academic/" target="_blank" rel="noopener">Academic theme</a> for
    <a href="https://gohugo.io" target="_blank" rel="noopener">Hugo</a>.

    
    <span class="float-right" aria-hidden="true">
      <a href="#" class="back-to-top">
        <span class="button_icon">
          <i class="fas fa-chevron-up fa-2x"></i>
        </span>
      </a>
    </span>
    
  </p>
</footer>

  </div>
  

  
<div id="modal" class="modal fade" role="dialog">
  <div class="modal-dialog">
    <div class="modal-content">
      <div class="modal-header">
        <h5 class="modal-title">Cite</h5>
        <button type="button" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body">
        <pre><code class="tex hljs"></code></pre>
      </div>
      <div class="modal-footer">
        <a class="btn btn-outline-primary my-1 js-copy-cite" href="#" target="_blank">
          <i class="fas fa-copy"></i> Copy
        </a>
        <a class="btn btn-outline-primary my-1 js-download-cite" href="#" target="_blank">
          <i class="fas fa-download"></i> Download
        </a>
        <div id="modal-error"></div>
      </div>
    </div>
  </div>
</div>

</body>
</html>
